---
title             : "fractalRegression: An R package for multiscale regression and fractal analyses"
shorttitle        : "FRACTAL REGRESSION"
author: 
  - name          : "Aaron D. Likens"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Division of Biomechanics and Research Development, Department of Biomechanics, and Center for Research in Human Movement Variability, University of Nebraska at Omaha,6160 University Dr S,Omaha, 68182, NE, USA."
    email         : "alikens@unomaha.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Software
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Travis J. Wiltshire"
    affiliation   : "2"
    role:
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
      - Software
affiliation:
  - id            : "1"
    institution   : "Department of Biomechanics, University of Nebraska at Omaha"
  - id            : "2"
    institution   : "Department of Cognitive Science & Artificial Intelligence, Tilburg University"
abstract: |
  Time series data from scientific fields as diverse as astrophysics, economics, human movement science, and neuroscience all exhibit fractal properties. That is, these time series often exhibit self-similarity and long-range correlations. This `fractalRegression` package implements a number of univariate and bivariate time series tools appropriate for analyzing noisy data exhibiting these properties. These methods, especially the bivariate tools [@kristoufekDetrendedFluctuationAnalysis2015; @likensStatisticalPropertiesMultiscale2019] have yet to be implemented in an open source and complete package for the R Statistical Software environment. As both practitioners and developers of these methods, we expect these tools will be of interest to a wide audience of scientists who use R, especially those from fields such as the human movement, cognitive, and other behavioral sciences. The algorithms have been developed in C++ using the popular Rcpp [@eddelbuettelRcppSeamlessIntegration2011] and RcppArmadillo [@eddelbuettelRcppArmadilloAcceleratingHighperformance2014] packages. The result is a collection of efficient functions that perform well even on long time series (e.g., $\geq$ 10,000 data points). In this work, we introduce the package, each of the functions, and give examples of their use as well as issues to consider to correctly use these methods.
  
  
  <!-- https://tinyurl.com/ybremelq -->
keywords          : "long range correlation, fractal, multiscale, dynamical systems"
wordcount         : "6,888"
bibliography      : ["library.bib"]
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  markdown: 
    wrap: 72
    canonical: true
---

```{r setup, include = FALSE}
library("papaja")
library("fractalRegression")
library("ggplot2")
library("kableExtra")
library("fracdiff")
library("segmented")
library("kableExtra")
library("tidyverse")
r_refs("library.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(424242)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

Over time, many signals from living and complex systems exhibit
systematic regularities and dependencies across spatial and temporal
scales [@kelloScalingLawsCognitive2010]. These regularities often follow
a power-law (i.e., self-similarity across scales) that are estimated
using fractal analyses. Fractal analysis, in its many forms, has become
an important framework in virtually every area of science, often serving
as an indicator of system health
[@goldbergerFractalDynamicsPhysiology2002], adaptability
[@bakSelforganizedCriticalityExplanation1987], control
[@likensExperimentalControlScaling2015], cognitive function
[@eulerWorkingMemoryPerformance2016], and multi-scale interactions
[@kelty-stephenThreadingMultifractalSocial2017].

In particular, various methods related to Detrended Fluctuation Analysis
(DFA) [@pengMosaicOrganizationDNA1994] have rose to prominence due to
their relative ease of understanding and broad applicability to
stationary and non-stationary time series, alike. More specifically, in
areas of the social and cognitive sciences, DFA, or variants of DFA,
have been used to study, for example, reaction times
[@vanordenSelforganizationCognitivePerformance2003], eye gaze
[@stephenDynamicsInsightMathematical2009], gait
[@hausdorffFractalDynamicsHuman1996;
@delignieresFractalDynamicsHuman2009], limb movements
[@delignieresFractalModelsEventbased2008], heart rate
[@goldbergerFractalDynamicsPhysiology2002], and neurophysiological
oscillations [@hardstoneDetrendedFluctuationAnalysis2012;
@schaworonkowLongitudinalChangesAperiodic2021;
@eulerWorkingMemoryPerformance2016]. Beyond an individual level, the
methods have been used to study human-machine system interaction
[@likensExperimentalControlScaling2015], tool use
[@kelty-stephenMultifractalTemporalCorrelations2016;
@favelaCognitiveScienceComplexity2020], and interpersonal coordination
in a variety of modalities
[@davisMultiscaleInteractionsInterpersonal2016;
@delignieresMultifractalSignaturesComplexity2016].

Thus, there is a broad scientific appeal for these fractal-based
analyses. While, the basic DFA algorithm has been implemented in
numerous packages and software programs, more advanced methods such as
Multifractal Detrended Fluctuation Analysis (MFDFA)
[@kantelhardtMultifractalDetrendedFluctuation2002], Detrended Cross
Correlation Analysis (DCCA)
[@zebendeDCCACrosscorrelationCoefficient2011;
@podobnikDetrendedCrossCorrelationAnalysis2008], and, in particular,
fractal regression techniques such as Multiscale Regression Analysis
(MRA) [@kristoufekDetrendedFluctuationAnalysis2015;
@likensStatisticalPropertiesMultiscale2019] have not yet been
implemented in a comprehensive software package. A key aspect of this
effort is to draw more attention and make more available these *fractal
regression* techniques. In particular, we find these methods widely
promising because they allow for uncovering "the time scales most
relevant to relationships between a system's components" (p. 2) within a
predictive framework [@likensStatisticalPropertiesMultiscale2019].

Thus, there is a clear need for a package that incorporates this
functionality in order to advance theoretical research focused on
understanding the time varying properties of natural phenomena and
applied research that uses those insights in important and diverse areas
such as healthcare [@cavanaugh2017] and education [@snow2016]. In this
work, we provide an overview of our `fractalRegression` package, provide
simulated and empirical examples of its functions, and provide practical
advice on the successful application of these methods.

# Package Overview

Our `fractalRegression` package for R
[@rcoreteamLanguageEnvironmentStatistical2018] is built for speed, based
on a C++ architecture and includes a variety of uni- and bivariate
fractal methods as well as functions for simulating data with known
fractional properties (e.g., scaling, dependence, etc.), and surrogate
testing. Some foundational efforts in fractal analyses, which partially
overlap with the functionality of this package, have been implemented
elsewhere. For example, a number of univariate fractal and multifractal
analyses have been implemented in the 'fracLab' library for MATLAB
[@legrand2003] and other toolboxes that are mainly targeted at
multifractal analysis [@ihlen2010;
@ihlenIntroductionMultifractalDetrended2012]. In terms of open access
packages, there are other packages that implement some, but not all of
the same functions such as the `fathon` package [@bianchi2020] that has
been implemented in Python as well as the R packages: `fractal`
[defunct], `nonlinearTseries`
[@garciaNonlinearTseriesNonlinearTime2020], and `MFDFA`
[@laibMultifractalAnalysisTime2018]. However, none of the above packages
incorporate univariate monofractal and multifractal DFA with bivariate
DCCA and MRA and some are only written in base R code, which can be less
efficient for long time series. Our `fractalRegression` package is
unique in this combination of analyses and efficiency (particularly for
long time series). For instance, we are not aware of any other packages
that feature MRA. In addition, we expect that featuring simulation
methods as well as surrogate testing strongly bolsters the accessibility
of these methods for the social and cognitive science community in
particular, but also science, more generally. An overview of the core
functions included in the package, the general objective of that
function, and the output are shown below in Table 1. Note that there are
some additional helper and plotting functions included as well. The
additional details are included in the sections corresponding to those
methods, in the package documentation, and in the original sources for
the methods.

**Table 1.**

*Overview of core package functions, objectives, and output*

| Function      | Objective                                                                                                   | Output                                                                                                                                                                                                                                       |
|-------------------|-------------------|----------------------------------|
| `dfa()`       | Estimate long-range correlation in a time series                                                            | Object containing the overall $\alpha$ estimate and, if desired the `logScales` and `logRMS`                                                                                                                                                 |
| `mfdfa()`     | Estimate the magnitude and range of long-range correlations in a time series                                | Object containing the $\log$ scales used for the analysis, the $\log$ fluctuation function for each scale and $q$, the various q-order exponents, $Hq$, $Tau$, $h$, and $Dh$. The base of $log$ depends on scale construction and user input |
| `dcca()`      | Estimates of scale-specific correlation between two time-series                                             | Object containing the scales used for the analysis and the $\rho$ '`rho'` values for each scale                                                                                                                                              |
| `mra()`       | Estimates the scale specific regression coefficients for a predictor time series on and outcome time series | Object containing the scales and scale specific $\beta$ estimates and $R^2$.                                                                                                                                                                 |
| `fgn_sim()`   | Simulate univariate fractional Gaussian noise                                                               | Returns a vector of length `N` according to the specified `H` Hurst exponent                                                                                                                                                                 |
| `mBm_mGn()`   | Simulate univariate multi-fractional Brownian motion and Gaussian noise                                     | Returns two vectors of length `N` according to the specified $H_t$ series                                                                                                                                                                    |
| `mc_ARFIMA()` | Simulate various types of bivariate correlated noise processes.                                             | Returns two vectors of length `N` according to the specified noise `process` and parameters                                                                                                                                                  |
| `iaaft()`     | Generate surrogate series using the iterative amplitude adjusted Fourier transform                          | Returns a vector of same length as input time series                                                                                                                                                                                         |

: **Table 1.** *Overview of core package functions, objectives, and
output*

# Methodological Details and Examples

In order to demonstrate the methods within the `fractalRegression`
package, we group this into univariate (DFA, MFDFA) and bivariate
methods (DCCA, MRA). For each method, we 1) highlight the key
question(s) that can be answered with that method, 2) briefly describe
the algorithm with references to additional details (see also Appendix 1
for fundamental equations), 3) describe some key considerations for
appropriately applying the algorithm, and demonstrate the use of the
functions on a 4) simulated and 5) empirical example. Note that all
code, data, and text are part of a reproducible manuscript that are
accessible at the following link:
<https://github.com/travisjwiltshire/fractal_regression_manuscript>.

## Univariate Methods

### Detrended Fluctuation Analysis

A key question that can be answered by Detrended Fluctuation Analysis
(DFA) [@pengMosaicOrganizationDNA1994] is: *what is the magnitude and
direction of long range correlation in a single time series?* While DFA
has been described extensively
[@kantelhardtDetectingLongrangeCorrelations2001] and visualized nicely
elsewhere [@kelty-stephenMultifractalTemporalCorrelations2016], we
provide a brief summary here. DFA entails splitting a time series into
several small bins (e.g., 16). In each bin, a least squares regression
is fit and subtracted within each window. Residuals are squared and
averaged within each window. Then, the square root is taken of the
average squared residual across all windows of a given size. This
process repeats for larger window sizes, growing by, say a power of 2,
up to $N/4$, where $N$ is the length of the series. In a final step, the
logarithm of those scaled root mean squared residuals (i.e.,
fluctuations) is regressed on the logarithm of window sizes. The slope
of this line is termed $\alpha$ and it provides a measure of the long
range correlation. $\alpha$ is commonly used an as estimator of the
Hurst exponent ($H$), where $\alpha<1$ = $H$, and for $\alpha>1$,
$H = 1 - \alpha$. Conventional interpretation of $\alpha$ is:
$\alpha < 0.5$ is anti-correlated, $\alpha ~= 0.5$ is uncorrelated,
white noise, $\alpha > 0.5$ is temporally correlated, $\alpha ~= 1$ is
long-range correlated, 1/f-noise, pink noise, $\alpha > 1$ is
non-stationary where the special case $\alpha ~= 1.5$ is fractional
Brownian noise. More generally, $1<\alpha<2$ are referred to as
fractional Brownian motion.

#### DFA Examples

To demonstrate the use of `dfa()` we simulate three time series using
the `fgn_sim()` function. This is a simple function based on the former
`fARMA` R package [defunct]. It requires the number of observations `n`,
and the Hurst exponent `H`. In particular, we simulate white noise, pink
noise, and anti-correlated fractional Gaussian noise using the code
below.

```{r, echo = TRUE}

white.noise <- fgn_sim(n = 5000, H = 0.5)

pink.noise <- fgn_sim(n = 5000, H = 0.9)

anti.corr.noise <- fgn_sim(n = 5000, H = 0.25)
```

Then, we run DFA on those simulated series using the example code below.
Note that this example uses linear detrending with minimum scale of 16,
a maximum scale that is at most 1/4 the time series length, and scale
factor (`scale_ratio`) of 2, which is evenly spaced in the logarithmic
domain (see General Discussion for more details and considerations for
these parameter choices).

```{r, echo = TRUE}
scales <- logscale(scale_min = 16, scale_max = 1024, scale_ratio = 2)

dfa.white <- dfa(x = white.noise, order = 1, verbose = 1, 
scales=scales, scale_ratio = 2)

dfa.pink <- dfa(x = pink.noise, order = 1, verbose = 1,
scales = scales, scale_ratio = 2)

dfa.anti.corr <- dfa(x = anti.corr.noise, order = 1, verbose = 1, 
scales = scales, scale_ratio = 2)
```

In terms of output from the above examples, for white noise, we observed
that $\alpha$ = `r dfa.white$alpha`, for pink noise we observed that
$\alpha$ = `r dfa.pink$alpha`, and since we simulated anti-correlated
noise with $H = 0.25$, we observed a close estimate of $\alpha$ =
`r dfa.anti.corr$alpha`. In terms of the objects saved from the `dfa()`
function, one commonly inspects the log(scales)-log(fluctuation) plots,
which we generate from our package using the `dfa.plot()` function.
Given the estimates above, we see in Figure 1 that the slopes for white
noise, pink noise, and anti-correlated noise conform to our
expectations. These slope estimates (and $R^2$) are provided in the
equation listed above each respective line.

```{r echo=FALSE, fig.height=7, fig.width=6}
par(mfrow=c(3,1))
dfa.plot(dfa.white)
dfa.plot(dfa.pink)
dfa.plot(dfa.anti.corr)
```

**Figure 1.** *Log scale-Log fluctuation plots for white noise (top),
pink noise (middle), and anti-correlated noise (bottom)*

For an empirical example, we apply the `dfa()` function to the Human
Balance Dataset [@santos2016]. This publicly available dataset includes
signals from a force platform that measures the center of pressure in
the x and y dimensions for 87 young adults (we exclude the older adults
from our analyses for simplicity). Trials lasted 60s. See original paper
for additional details on data processing [@santos2016]. For the
empirical examples, we use two different time series featuring a
participant standing on a firm (rigid) surface with eyes open and a foam
(unstable) surface with eyes open. We chose this dataset because
postural sway data are known to exhibit interesting fractal dynamics
[@collins1993; @delignières2011;
@delignieresTransitionPersistentAntiPersistent2011] and we can
systematically evaluate the data for all of the univariate and bivariate
analyses included in the package.

For center of pressure (COP) data, we take the first order differences
of each series using the `diff()` function as a rough approximation of
COP velocity. For the univariate analyses, we focus on analyses of the
COP data in the x dimension. Then, we define the appropriate scales for
the analyses using the same methods shown above, except we use a
`scale ratio = 1.1` for a higher density of points. Figure 2 shows the
results of these analyses.

```{r, echo = FALSE}
open_firm <- read.csv("./BDS00001.csv")
open_foam <- read.csv("./BDS00007.csv")
open_firm_copx_diff <- diff(open_firm$X.COPx.)
open_firm_copy_diff <- diff(open_firm$X.COPy.)
open_foam_copx_diff <- diff(open_foam$X.COPx.)
open_foam_copy_diff <- diff(open_foam$X.COPy.)
```

```{r echo=FALSE, fig.height=6, fig.width=6}
scales <- logscale(scale_min = 16, scale_max = length(open_firm_copx_diff)/4, scale_ratio = 1.1)

open_firm_copx_diff_dfa <- dfa(open_firm_copx_diff, order = 1, scales = scales, verbose = 1)


open_foam_copx_diff_dfa <- dfa(open_foam_copx_diff, order = 1, scales = scales, verbose = 1)

par(mfrow=c(2,1))
dfa.plot(open_firm_copx_diff_dfa)
dfa.plot(open_foam_copx_diff_dfa)
```

**Figure 2.** *Log scale-Log fluctuation plots for empirical differenced
COPx time series for rigid/firm (top) and unstable/foam (bottom)
surfaces.*

Importantly, regarding the question one can ask using DFA, we observe
from Figure 2, that long range correlations are positive and
approximately `r open_firm_copx_diff_dfa$alpha` -
`r open_foam_copx_diff_dfa$alpha`. However, from visual inspection of
these plots we observe that two slopes might fit better than one for
these time series; a phenomenon known as crossover points [@collins1993;
@ge2013]. One common approach when such crossover points exist is to
recognize that the signal might be best characterized by two scaling
regions, before and after an inflection point. We provide an example of
how to check for where the break point is below using piece-wise
regression .

```{r, echo = TRUE}
# requires the segmented R package

dfa.mod <- lm(log_rms ~ log_scales, data = open_firm_copx_diff_dfa)

seg <- segmented(dfa.mod, seg.Z = ~log_scales)

```

```{r, echo=FALSE}

plot(open_firm_copx_diff_dfa$log_scale,open_firm_copx_diff_dfa$log_rms, pch=16, ylab="logF(s)", xlab = "log(s)")

plot(seg,add=T, lwd=2,col="red")
```

**Figure 3.** *Log scale-Log fluctuation plots for empirical differenced
COPx time series for rigid/firm surfaces with lines plotted for
piece-wise regression slopes*

In the example above, we observe a crossover point at around the scale
size of log 6. And, from the results in Table 2 below, we observe that
there are two distinct scaling relationships corresponding to $\alpha =$
1.36 and $\alpha =$ 0.43, respectively. This is a well known result in
the postural control literature such that short time scales exhibit a
persistent temporal correlation and that longer time scales exhibit an
anti-persistent correlation. More substantively, short time scale
dynamics correspond to periods of exploratory sway, whereas longer time
scales correspond to corrective movements that prevent exceeding the
base of support and falling [@collins1993; @delignières2011;
@delignieresTransitionPersistentAntiPersistent2011].

**Table 2.** *Results from piece-wise regression analysis*

|         | Estimate | SE   | *t*   | 95% CI l | 95% CI u |
|---------|----------|------|-------|----------|----------|
| Slope 1 | 1.36     | 0.03 | 40.66 | 1.30     | 0.40     |
| Slope 2 | 0.43     | 0.01 | 31.25 | 1.43     | 0.45     |

: Results from piece-wise regression analysis

```{r echo=FALSE}
#slope(seg)
#tab_2 <- data.frame(Estimate = c("1.36", "0.43"),
#                    SE = c("0.03", "0.01"),
#                    t = c("40.66", "31.25"),
#                    CIl = c("1.30","0.40"),
 #                   CIu = c("1.43","0.45"))
#kable(tab_2, 
#      booktabs=TRUE,
#      escape = FALSE,
 #     col.names = c("Estimate", "SE", "\\textit{t}","95% CI l","95% CI u"),
 #     align = c("l","c","c","c", "c"),
#      caption = "Table 2. Results from piece-wise-regression analysis")  %>%
#  row_spec(row = 0, align = "c") %>%
#  kable_styling(full_width = TRUE)
```

### Multifractal Detrended Fluctuation Analysis

Multifractal Detrended Fluctuation Analysis (MFDFA;
@kantelhardtMultifractalDetrendedFluctuation2002) is an extension of DFA
by generalizing the fluctuation function to a range of exponents of the
$q$th order. The key question that can be answered by MFDFA is: *how
does the magnitude and direction of long range correlation change over
time within a single time series?* Like DFA, MFDFA entails splitting a
time series into several small bins (e.g., 16). In each bin, least
squares regression is fit and subtracted within each window. However,
the residuals are raised to a range of exponents $q$ and averaged within
each window. So when $q = 2$, MFDFA reduces to ordinary DFA. When
$q >2$, relatively larger residuals are emphasized and when $q < 2$,
relatively smaller residuals are emphasized. The rest of the DFA
algorithm is performed for each window and windows size for all values
of $q$. We refer the reader to the work of Kelty-Stephens and
colleagues' [@kelty-stephenMultifractalTemporalCorrelations2016] Figure
3 for a visualization of the algorithm, Appendix 1 of this paper for
fundamental equations, and Kantelhardt and colleagues' work
[@kantelhardtMultifractalDetrendedFluctuation2002] for additional
mathematical description.

#### MFDFA Examples

To demonstrate the use of `mfdfa()`, we work with data included in our
package (`fractaldata`), that was originally provided by
@ihlenIntroductionMultifractalDetrended2012. It includes a white noise
time series, a monofractal time series, and a multifractal time series.
These data are shown below in Figure 4.

```{r, echo=FALSE}
# Load the data
data("fractaldata")

white.plot <- ggplot(fractaldata, aes(y=whitenoise, x=time))+geom_line()+ggtitle("White Noise")+ylab("")

mono.plot <- ggplot(fractaldata, aes(y=monofractal, x=time))+geom_line()+ggtitle("Monofractal")+ylab("Amplitude (a.u.)")

multi.plot <- ggplot(fractaldata, aes(y=multifractal, x=time))+geom_line()+ggtitle("Multifractal")+ylab("")

gridExtra::grid.arrange(white.plot,mono.plot,multi.plot,nrow=3)
```

**Figure 4.** *Time series from Ihlen (2012) corresponding to white
noise, monofractal, and multifractal series*

Performing MFDFA is straight forward with the `mfdfa()` function. As
shown in the example below, one enters the time series `x` to perform
the analysis on, the range of `q` order exponents to use, the `order` of
polynomial detrending, and the `scales` for the analysis. In this case,
we define our `scales` by choosing logarithmically spaced scales and we
select values of q from -5 to 5. Note here that the scale factor need
not be a power of two but should be evenly spaced in the logarithmic
domain by, for example, using different logarithm bases. We provide the
`logscale()` function to facilitate scale construction.

```{r, echo=TRUE}

scales <- logscale(scale_min = 16,scale_max = 1024,scale_ratio = 1.1)

white.mf.dfa.out <- mfdfa(x = fractaldata$whitenoise, q = c(-5:5), 
order = 1, scales=scales, scale_ratio=1.1)

mono.mf.dfa.out <- mfdfa(x = fractaldata$monofractal, q = c(-5:5),
order = 1,  scales=scales, scale_ratio=1.1)

multi.mf.dfa.out <- mfdfa(x = fractaldata$multifractal, q = c(-5:5),
order = 1,  scales=scales, scale_ratio=1.1)

```

A common way to understand if there is evidence of multifractality is to
examine a plot showing the slopes of the `log_fq` at the `log_scale`
values. If all the lines have the same slope, that provides evidence of
monofractality. If there are distinct slopes, then there is evidence of
multifractality. It's also important to check here that the slopes of
`log_scale` and `log_fq` are approximately linear, thus implying that
they are scale invariant. If not, then it could be the case that a
higher order polynomial detrending is appropriate (see Kantelhardt et
al., 2001). Figure 5, in the top left quadrants, shows what we would
expect for a monofractal and multifractal signal. In other words, the
monofractal signal shows a consistent slope, whereas the multifractal
signal shows variability in the slopes. Importantly, Figure 5, using our
`mfdfa.plot()` function, shows various aspects of mfdfa for each value
of q (each with its own color) and includes panels that show the
log(scale)-log(Fluctuation) plots like in the DFA plots (top left), the
slopes of those lines as the q-order Hurst exponents $H(q)$ for each
value of q (top right), the mass exponents ($\tau(q)$) for each value of
q (bottom left), and the multifractal spectrum showing q-order
singularity values (h) for their dimension (D(h) for each value of q
(bottom right). See Ihlen (2012) for additional details of these
metrics.

```{r echo=FALSE, message=FALSE}
mfdfa.plot(mono.mf.dfa.out, do.surrogate = FALSE)
mfdfa.plot(multi.mf.dfa.out, do.surrogate = FALSE)
```

**Figure 5.** *mfdfa.plots for mono-(top) and multifractal series
(bottom).*

A common metric for comparing multifractal spectra is to calculate the
width ($W$) as $h_{max} - h_{min}$. Let's do this to compare the
monofractal and multifractal time series. We observe in this case that
for the monofractal signal $W_{mono} =$
`r max(mono.mf.dfa.out$h) - min(mono.mf.dfa.out$h)` and $W_{multi} =$
`r max(multi.mf.dfa.out$h) - min(multi.mf.dfa.out$h)`. If we compare the
spectra for the mono- and multifractal signals above (bottom right of
both plots), we observe this clear difference in the widths of the
multifractal spectra for the signals.

```{r}
scales <- logscale(scale_min=16, scale_max=length(open_firm_copx_diff)/4,scale_ratio=1.1)

open_firm_copx_diff_mfdfa <- mfdfa(open_firm_copx_diff, q = -5:5, order = 1, scales=scales, scale_ratio=1.1)

open_foam_copx_diff_mfdfa <- mfdfa(x=open_foam_copx_diff, q = -5:5, order = 1, scales=scales, scale_ratio=1.1)
```

For our empirical analysis, we again turn to the postural data. We set
our parameters appropriate for the data and run `mfdfa()` on the
differenced COPx data for the firm and foam surfaces. Figure 6 shows the
plots for these analyses. In particular, we observe for both surfaces
that the q-order Hurst exponents range from
`r min(c(open_firm_copx_diff_mfdfa$Hq,open_foam_copx_diff_mfdfa$Hq))` -
`r max(c(open_firm_copx_diff_mfdfa$Hq,open_foam_copx_diff_mfdfa$Hq))`,
all suggesting positive long-range correlations with a weakening of the
strength at larger values of q (i.e., trending towards white noise). The
multifractal spectrum widths of the two surfaces were also similar,
$W_{foam} =$
`r max(open_foam_copx_diff_mfdfa$h) - min(open_foam_copx_diff_mfdfa$h)`
and $W_{firm} =$
`r max(open_firm_copx_diff_mfdfa$h) - min(open_firm_copx_diff_mfdfa$h)`.

```{r message=FALSE, warning=FALSE}
mfdfa.plot(open_firm_copx_diff_mfdfa, do.surrogate = FALSE)
mfdfa.plot(open_foam_copx_diff_mfdfa, do.surrogate = FALSE)
```

**Figure 6. m***fdfa.plots for the firm (top) and foam surfaces
(bottom).*

## Bivariate Methods

### Detrended Cross-Correlation Analysis

Detrended Cross-Correlation Analysis (DCCA
[@podobnikDetrendedCrossCorrelationAnalysis2008;
@zebendeDCCACrosscorrelationCoefficient2011] is a bivariate extension of
the DFA algorithm generalizing it to a correlational case between two
time series that may be non-stationary. The key questions that can be
asked with it are: a) *How does the correlation between two time series
change as a function of scale?* and b) *What is/are the dominant (time)
scale(s) of coordination?* Such decisions are based on a predetermined
threshold such as a conventional statistical significance as we
demonstrate below. Researchers may also select other criteria
appropriate for their research area.The DCCA algorithm is a direct
generalization of the DFA algorithm but applied to two concomitantly
measured time series, say *x* and *y*. As in DFA, time series are split
into multiple bins and detrended using least squares regression.
Separate regressions are performed for *x* and *y*. Within each bin,
three quantities are estimated, the average squared residual of *x,* the
average squared residual of *y*, and the average cross product (i.e.,
the covariance) between the residuals for *x* and the residuals for *y*.
Each of those quantities is averaged across all bins of a given size.
After taking the squared residual for *x* and *y*, we obtain scale-wise
equivalents of covariance $F_{xy}(s)$ and standard deviations for *x*
$F_x(s)$ and *y* $F_y(s)$. The use of $F$ to designate these quantities
derives from originating literature [@kristoufek2015; @likens2019].
Thus, the scale-wise regression coefficient, the estimand of DCCA, is
the following quotient:

$$\rho(s)=\frac{F_{xy}(s)}{F_x(s)F_y(s)}$$

Simplified, in DFA, the key metric is $\alpha$, but in DCCA, one
estimates the scale-specific, detrended cross-correlation coefficient
$\rho(s)$ for the pair of time series.

#### DCCA Examples

To demonstrate the use of `dcca()`, we used the `mc_arfima()` function
from our package to simulate two time series with known properties.
Specifically, we use the multicorrelated ARFIMA examples from
Kristoufek's work [@kristoufekMixedcorrelatedARFIMAProcesses2013]. In
this case, we use the parameters from Kristoufek (2013) for Model 1 (p.
6,487), that generates two time series of length 10,000 that exhibit
long range correlations (LRC) as well as long range cross-correlations
(LRCC). The code for simulating these two time series is shown below.
Additionally, Figure 7, shown below, visualizes a subset of these time
series.

```{r echo = TRUE, message=FALSE}
set.seed(987345757)

sim1 <- mc_ARFIMA(process="Mixed_ARFIMA_ARFIMA", alpha = 0.2, 
beta = 1, gamma = 1, delta = 0.2, n = 10000, d1 = 0.4, d2 = 0.3, 
d3 = 0.3, d4=0.4, rho=0.9)

```

```{r, echo=FALSE}

plot(sim1[2000:3000,1],type='l', ylab= "Signal Amplitude", xlab='Time', main = "MC-ARFIMA with LRC and LRCC")

lines(sim1[2000:3000,2], col='blue')
```

**Figure 7.** *Subset of two time series exhibiting long range
correlation and long range cross-correlation.*

As can be seen in Figure 7, the simulated time series, although quite
noisy, appear to covary over time with similar trends. To perform the
`dcca()` on these time series, we use the code below, where we first
define the `scales` using the `logscale()` function described earlier
along with the `dcca()` function itself.

```{r echo = TRUE}
scales <- logscale(scale_min = 10, scale_max = 1000, scale_ratio = 1.1)

dcca.out.arfima <- dcca(sim1[,1], sim1[,2], order = 1, scales = scales)
```

Next, we visualize the output of DCCA in Figure 8. We observe that, as
expected, the correlation between the MC-ARFIMA processes are
consistently high (all $\rho$'s $> .8$) and continue to be high at
increasing time scales.

```{r, echo=FALSE}

dcca.plot(dcca.out.arfima, order = 1, ci = FALSE, iterations = NULL, return.ci = FALSE)

```

**Figure 8.** *DCCA output for long range correlation and long range
cross-correlation.*

Figure 8 is difficult to interpret on its own. To address this, we
demonstrate an additional plot and analysis feature of `dcca()` by
modifying the above code as shown below `ci = TRUE`. Loess smoothing can
also be applied to both $\rho(s)$ and its confidence intervals using
`loess.rho = TRUE` and `loess.ci = TRUE`. Those latter options are
useful for reducing the impact of increasing variance on estimates of
$\rho(s)$ at large scales [@likens2019]. Note though that a much larger
set of calculations takes place and may take several seconds up to
several minutes (for long time series) to complete. This method is shown
in Figure 9. Importantly, it shows us that there is evidence of long
range cross-correlations as there $\rho(s)$ for all scales are outside
of the surrogate confidence interval.

```{r, echo = FALSE}
dcca.plot(dcca.out.arfima, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.rho = TRUE, loess.ci = TRUE)
```

**Figure 9.** *DCCA output for long range correlation and long range
cross-correlation with Loess smoothing on estimates and a surrogate
confidence interval.*

As a point of comparison, we can generate a time series in contrast with
that example that exhibit processes with LRC and short-range
cross-correlation (SRCC) using the code below. In contrast to the
previous DCCA analysis, Figure 10 shows a signal that begins with a high
cross-correlation ($\rho$'s $\approx .6$), but that begins to deviate
and trend substantially lower at increasing scale sizes with $\rho$
entering the confidence interval containing 0. In fact, based on the
plotted confidence intervals, the correlation between the two series
becomes non-significant from a conventional standpoint.

```{r}
set.seed(98732346)
sim2 <- mc_ARFIMA(process="Mixed_ARFIMA_AR", alpha = 1,beta = 1,gamma = 1,delta = 1,n =10000,d1=0.4,d2=0.4,theta1=0.8,theta2=0.8,rho=0.9)
```

```{r, echo=FALSE}
scales <- logscale(scale_min = 10, scale_max = 1000, scale_ratio = 1.1)
dcca.out.arfima2 <- dcca(sim2[,1], sim2[,2], order = 1, scales = scales)
dcca.plot(dcca.out.arfima2, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.rho = TRUE, loess.ci = TRUE)

```

**Figure 10.** *DCCA output for long range correlation and short range
cross-correlation including smoothing and a surrogate confidence
interval.*

Turning next to the empirical balance data, we apply DCCA to the
differenced COPx *and* COPy data for the firm and foam platforms. We
again set appropriate values for `scales` and apply the `dcca()`
function to the pair of time series.

```{r echo=FALSE}
scales <- logscale(scale_min=16, scale_max=length(open_firm_copx_diff)/4,scale_ratio=1.1)

dcca.out.open.firm <- dcca(open_firm_copx_diff, open_firm_copy_diff, order = 1, scales = scales)

dcca.out.open.foam <- dcca(open_foam_copx_diff, open_foam_copy_diff, order = 1, scales = scales)

```

```{r echo=FALSE}
dcca.plot(dcca.out.open.firm, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.rho = TRUE, loess.ci = TRUE)

dcca.plot(dcca.out.open.foam, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.rho = TRUE, loess.ci = TRUE)

```

**Figure 11.** *DCCA output for empirical COPx and COPy balance data for
the eyes open while standing on the firm surface (top) and foam surface
(bottom)*

In examining the output from these analyses, Figure 11 shows a clear
difference between the two conditions. First, in the firm platform
example, the $\rho(s)$ values are much greater than in the foam
condition with the max $\rho(s)$ = `r max(dcca.out.open.firm$rho)`
compared to `r max(dcca.out.open.foam$rho)` for the foam condition.
Second, we observe for the foam example, that the time scale of maximum
correlation is
`r dcca.out.open.firm$scales[which.max(dcca.out.open.firm$rho)]`, which
is a larger time scale when compared to the foam example, which had a
maximum correlation at scale
`r dcca.out.open.foam$scales[which.max(dcca.out.open.foam$rho)]`. Third,
the pattern of change in correlation across scales is slightly
different. The firm example is higher overall; it starts relatively low
at very small time scales before a rapid increase and then steady
decrease before stabilizing at increasingly larger scales. By contrast,
the foam example has relatively lower overall correlation values, the
smallest scale is the highest followed by a steady decrease and then
also stabilizing at larger scales. Lastly, we can also derive
statistical conclusions because, in the firm condition, the two series
are correlated at all scales, whereas the series are only correlated
beyond chance at the smaller scales in the foam condition.

### Multiscale Regression Analysis

Multiscale regression analysis (MRA) is a further generalization of DCCA
that brings the analyses into a predictive, regression framework
[@kristoufek2015]. The key questions that can be answered by it are: a)
*How does the influence of one time series on another time series change
as a function of scale?* and b) *What is/are the dominant (time)
scale(s) of influence of one time series on another time series?* The
algorithm is largely the same as DCCA, with a key difference being that
instead of estimating scale-wise symmetric correlation coefficients,
leveraging methods of Ordinary Least Squares (OLS) regression,
asymmetric $\beta$ coefficients are estimated [@likens2019;
@kristoufek2015] according to the following equation:

$$
\beta(s)=\frac{F_{xy}(s)}{F^2_x(s)}
$$

The $\beta(s)$ equation differs from the $\rho(s)$ equation only in the
denominator where $F^2_x(s)$ is the average squared residual at each
scale and $F_xy(s)$ is still the scale-wise covariance.

#### MRA Examples

Considering the LRC and LRCC simulations used for DCCA, we can examine
whether the scale-wise fluctuations of one variable can predict the
scale-wise fluctuations of the other using `mra()`. As with a
traditional regression approach, we will use one of our variables as our
predictor ($x_t$) and the other as our outcome ($y_t$). In the example
below, we again first define our logarithmically spaced scales. We then
apply the `mra()` function to the two simulated time series. In this
case, it's important to specify which is variable is `x` (the predictor)
and which is `y` (the outcome).

```{r echo = TRUE}
scales <- logscale(scale_min = 10, scale_max = 1000, scale_ratio = 1.1)

mra.out <- mra(x = sim1[,1], y = sim1[,2], order = 1, scales = scales)
```

We can then visualize these results as shown below in Figure 12.
Generally, we observe that the $\beta$ coefficients are relatively
stable at increasing time scales with a general, perhaps quadratically
increasing trend. Here it is also important to investigate the change in
$R^2$ as well as the $t$-values. Below we see that the $R^2$ is quite
high at most of the time scales with $R^2_{min} =$
`r round(min(mra.out$r2),2)` and $R^2_{max} =$
`r round(max(mra.out$r2),2)` and all $\beta(s)$ exceed the confidence

```{r echo=FALSE}
mra.plot(mra.out, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.beta = TRUE, loess.ci = TRUE)

```

intervals, implying conventional statistical significance. So between
these two component ARFIMA processes, the output of MRA shows that much
of the scale specific variance in $y_t$ is explained and predicted by
$x_t$.

**Figure 12.** *MRA output for long range correlation and long range
cross-correlation.*

```{r warning=FALSE, include=FALSE}
scales <- logscale(scale_min = 16, scale_max = length(open_firm_copx_diff)/4, scale_ratio = 1.1)

mra.firm.out.xy <- mra(open_firm_copx_diff, open_firm_copy_diff, order = 1, scales = scales)

mra.firm.out.yx <- mra(open_firm_copy_diff, open_firm_copx_diff, order = 1, scales = scales)
#open_foam_copx_diff, open_foam_copy_diff

```

Turning next to the empirical balance data, we can determine whether
postural adjustments in the COPx are predictive of adjustments in COPy,
and vice versa. This means that we use the `mra()` function two times
and reverse the order of entry for the x and y arguments to allow for
determining the degree to which each signal can predict the other across
scales. In Figure 13 below, we see the resulting $\beta$'s we observed
for the the balance data on the firm surface. Notably, the COPx
predicting COPy (max $\beta$ = `r max(mra.firm.out.xy$betas)`) has
noticeably smaller $\beta$ values compared to COPy predicting COPx (max
$\beta$ = `r max(mra.firm.out.yx$betas)`). Notice as well how Figure 13
(bottom), where adjustments in the y dimension are predicting
adjustments in the x dimension, resembles the DCCA plot for this
analysis (see Figure 11). Given the asymmetry in the magnitude of the
$\beta$s, this example suggests that postural adjustments in the y
dimension appear to be driving changes in the x dimension. And, there is
a clear time scale where this relationship is strongest at scales =
`r mra.firm.out.yx$scales[which.max(mra.firm.out.yx$betas)]`, implying a
dominant mode of coordination between mediolateral and anterioposterior
control processes.

```{r echo=FALSE}
mra.plot(mra.firm.out.xy, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.beta = TRUE, loess.ci = TRUE)
mra.plot(mra.firm.out.yx, order = 1, ci = TRUE, iterations = NULL, return.ci = FALSE, loess.beta = TRUE, loess.ci = TRUE)
```

**Figure 13.** *MRA output for balance data on foam surface with COPx
predicting COPy (top) and COPy predicting COPx (bottom).*

## Surrogate Methods

In all of the above methods, one gets either a single estimate of a
parameter (e.g., $\alpha$) or a range of estimates (e.g., $\rho(s)$,
$\beta(s)$). While those estimates are meaningful in and of themselves,
it is common practice to perform some form of null hypothesis test
regarding the estimate(s). These are generally referred to as surrogate
methods [@kantz2003]. We present several options here that could be
ranked in terms of increasing levels of rigor: randomized surrogates,
iterative amplitude adjusted Fourier transformed (IAAFT) surrogates, and
model-based surrogates.

### Randomized Surrogates

Randomized surrogates generally involve randomly shuffling the order of
values of a time series. The idea is generally that the temporal
structure is destroyed, yet the other features of the time series still
exist [@kantelhardtMultifractalDetrendedFluctuation2002]. The confidence
intervals for all of our plotting methods use this technique. Note that
additional options exist along these lines (see for example
[@dumasInterBrainSynchronizationSocial2010]). The key comparison here
would be to compare the estimates extracted from a given analysis (e.g.,
DFA) on the observed sample of data with the estimates derived from an
equally sized sample of the surrogate series [@kantz2003; @moulder2018;
@wiltshireMultiscaleMovementCoordination2019].

```{r echo = TRUE}
rand.surr <- permute::shuffle(pink.noise)

dfa.rand.surr <- dfa(x = rand.surr, order = 1, verbose = 1,
scales = scales, scale_ratio = 1.1)
```

Randomizing the pink noise time series, which originally exhibited long
range correlation ($\alpha$ = `r dfa.pink$alpha`), and performing DFA on
it, now provides an estimate of $\alpha$ = `r dfa.rand.surr$alpha`,
which is consistent with a random or white noise process. These values
are clearly different, however, performing inferential statistics on a
sample of observed estimates compared to surrogate estimates would
provide compelling evidence that the temporal dynamics suggested by the
observed estimates are different than those derived from a random
process.

### Iterative Amplitude-Adjusted Fourier Transform Surrogates (IAAFT)

The IAAFT algorithm was originally developed as a way to discern whether
nonlinearity is a feasible explanation for time series patterns
[@schreiber1996]. More recently, it was proposed as a technique to
determine if multifractal indices suggest interaction across scales
[@ihlen2010]. Like with randomized shuffling, estimates derived from
IAAFT surrogates should be also be different from the estimates derived
from the empirical time series. Although in this case, the comparison is
typically made between the multifractal spectra of the observed time
series, and the typical spectrum derived empirically from a set of IAAFT
surrogate series.

In the code below, we provide an example for generating IAAFT surrogates
using the `iaafft()` function in the package. One enters the `signal`,
which is the observed time series, and `N`, the number of surrogates to
generate. There are a number of options here, but a common number of
surrogates is 19 [@kantz2003], which allows one to establish a 95%
confidence interval. In practice, surrogates are generated from each
observed time series. Here we illustrate the process using only a single
time series: the multifractal signal used previously in the MFDFA
example. Then we use the same parameters for the `mfdfa()` function, but
apply it to all of the IAAFFT surrogates. Note also that surrogate
analysis is 'built-in' to our plot functions within the package as well
with options to return the relevant empirically derived confidence
intervals.

```{r echo = TRUE}

iaafft.surr <- iaafft(fractaldata$multifractal, N = 19)

iaafft.surr.out <- apply(iaafft.surr, MARGIN = 2, FUN = mfdfa, 
q = c(-5:5), order = 1, scales=scales, scale_ratio = 2)

```

```{r, echo=FALSE}
for (i in 1:length(iaafft.surr.out)){
  mf.width.temp <- max(iaafft.surr.out[[i]]$h) - min(iaafft.surr.out[[i]]$h)
  if (i == 1){
    mf.width <- mf.width.temp
  } else {
    mf.width <- rbind(mf.width,mf.width.temp)
  }
}
```

Assuming we were using IAAFFT to compare the multifractal width ($W$)
between the observed signal and the surrogate signals, recall that the
observed width was $W_{multi} =$
`r max(multi.mf.dfa.out$h) - min(multi.mf.dfa.out$h)`. Now, we can
calculate the average multifractal width across all of the generated
surrogates and we observe that $W_{surr} =$ `r mean(mf.width)`, which is
narrower than the spectrum from the multifractal signal. In practice,
there are many surrogate options [@moulder2018], but, again, inferential
statistics are commonly performed to compare observed estimates to the
surrogate estimates to bolster evidence of the inferred dynamics.

### Model-based Surrogates

Surrogates can also be generated when a theoretical model exists that
explains the data generating process for the observed time series.
Well-defined mathematical models of this nature are rare in behavioral
sciences, but useful because they allow for more targeted and
(potentially) realistic hypothesis testing of the underlying dynamics
and how they might change due to experimental constraints. We do not
provide a worked out example of such processes, but readers can consult
cited papers for examples of this kind [@likens2019;
@roumeWindowedDetrendedCrosscorrelation2018; @delignières2011].

# General Discussion

In this manuscript, we provided details about the first version of a new
R package aimed at bringing together a number of fractal methods that we
and other researchers have found useful in analyzing a range of
behavioral and physiological data. Indeed, these collective methods have
found utility in virtually every area of science. Despite that reach,
many researchers are still not aware of these methods or lack software
for their implementation. This `fractalRegression` package is our effort
to bridge those gaps by demonstrating each of several methods first with
simulated data, followed by equivalent demonstrations with human
movement data (only one of many possible use cases). This allows the
reader to see both the 'best case' scenario as well as the
idiosyncrasies that rear their heads when we transition from the
pristine world of simulation to the noisiness inherent in empirical
human behavioral data.

Taken together, these methods allow researchers to examine, in
univariate time series, the magnitude and direction of long range
correlation and/or how that magnitude and direction might change over
time. In bivariate cases, these methods allow for determining: (1) how
the correlation between time series changes as a function of scale and
(2) what the dominant (time) scale(s) of coordination are. Or,
relatedly, one can investigate how the influence of one time series on
another changes as a function of the scale of observation while
potentially identifying the dominant (time) scale(s) of influence. Thus,
these methods provide general value and can answer several types of
questions on many types of data. To do so effectively requires careful
and appropriate application, though. We next discuss some of these
considerations while also referring the reader to other helpful tutorial
material.

#### Practical considerations for univariate methods (DFA, MFDFA)

We recommend a few points of consideration in conducting DFA and MFDFA.
One is to be sure to evaluate whether there are cross-over points in the
log scale-log fluctuation plots [@pengMosaicOrganizationDNA1994;
@perakakis2009; @kantelhardtDetectingLongrangeCorrelations2001;
@likensStergiouTutorial2020; @likensExperimentalControlScaling2015].
Cross-over points (or a visible change in the slope as a function of
scale) indicate that a simple mono-fractal characterization does not
sufficiently characterize the data. If cross-over points are evident, we
recommend proceeding to estimate the two scaling regions with a
piece-wise regression (as we showed for the empirical DFA example).
Note, however, that for the empirical MFDFA example above, we did not
parse the signal for piece-wise MFDFA although some efforts have been
conducted for decomposing crossovers in multifractal signals
[@nagy2017]. Other suggestions are to only analyze a single linear
region [@ihlenIntroductionMultifractalDetrended2012]. Regardless, more
research is needed to understand the implications of crossover phenomena
with respect to the more complicated fluctuation functions of MFDFA.

While it is common to use only linear detrending with DFA, this is not
necessarily the best practice. Instead, a more rigorous approach
requires inspection of trends in the data to determine if a higher order
polynomial would be more appropriate for detrending. There are certainly
instances in the literature where DFA fluctuation plots show signs of
curvilinearity [@delignieresTransitionPersistentAntiPersistent2011].
Such curvilinearity could be interpreted as representing an inflection
point. In such cases, one can compare the DFA output for different
polynomial orders [@kantelhardtDetectingLongrangeCorrelations2001] to
determine if a genuine inflection point is present or if nonlinearity in
DFA and MFDFA emerges due to unadressed nonlinear trends in the original
series [@likens2019]. Indeed, one is not simply limited to OLS
detrending with polynomials. Many other propositions have been
introduced to generalize the idea of detrending function to other models
such as moving averages [@xuDetrendedMovingAverage2005] and even
non-parametric techniques like emprical mode decomposition
[@qianDFAwithEMD2011]. Those and other more 'exotic' detrending
techniques will be featured in future releases of this package (see
Development Plan below).

Another important matter concerns the length of the time series being
analyzed. Unfortunately, all of the methods presented in this manuscript
are relatively data hungry. The general trend is that estimation error
of various quantities detailed above grows dramatically as time series
length decreases [@delignieres2006]. That work and other simulation
studies have revealed that reliable estimates of fractal quantities
requires a minimum length of the time series of \~512 observations
although larger is better [@delignieres2006; @likens2019]. That
recommendation holds true for both univariate and bivariate cases,
alike. If multiple time series are to be compared, then it's also
important that they have matching lengths. Relatedly, general
recommendations for choosing the min and max scale are a minimum scale
of 10 and a maximum scale of N/4, where N is the total number of
observations in the signal. See
@ekeFractalCharacterizationComplexity2002 and
@gulichCriterionDeterminationOptimal2014 for additional considerations
but also keep in mind specific research areas may also have other
criteria [@damouras2010; @marmelat2019].

#### Practical considerations for bivariate methods (DCCA, MRA)

As suggested above, all of the above considerations also apply in the
bivariate case such as recommendations for length, scales sizes, and
detrending. This is not surprising given that those methods share a
common mathematical girding. However, given that the estimands in DCCA
and MRA are qualitatively different that those in DFA and/or MFDA, there
are likewise some unique issues as well. Regarding time series length,
previous research has shown that $\widehat{\beta}(s)$ is unbiased
regardless of series length and underlying distribution; however, it's
variance increases dramatically with decreasing time series length,
especially for large time scales [@likens2019]. This has important
consequences for evaluation of statistical significance of
$\widehat{\beta}(s)$ for large $s$. Namely, ever larger
$\widehat{\beta}(s)$ may be needed to exceed conventional levels of
significance (e.g., $p<.05$). While $\widehat{\beta}(s)$ is unbiased,
even for non-Gaussian, time series, that property does not hold in the
presence of trends (e.g., linear, quadratic) or nonstationarity. In both
those instances, $\widehat{\beta}(s)$ becomes positively biased, which
could imply spurious positive relationships between series if not
addressed. In both those instances, one promising remedy seems to be
higher order detrending polynomials (e.g., quadratic, cubic). This
remedy also seems to apply, even when the underlying increments of
nonstationary processes have non-Gaussian distributions. Therefore, it
is of utmost importance to inspect time series for strong time trends
(e.g., via OLS regression with various powers of time as a predictors)
and nonstationarity (e.g., Dickey-Fuller tests) so that a detrending
function of sufficient order can be selected for use in the analysis.

#### Development Plan

The current release version of the `fractalRegression` package features
all of the functions presented in Table 1. Other functions are also
currently available for research and development but should be
considered "works in progress" as they require additional testing but
will be elevated in future releases of the package. For example, lagged
versions of DCCA and MRA, known as Detrended Lagged Cross Correlation
Analysis (DLCCA) or Multiscale Lagged Regression Analysis (MLRA)
respectively, are forthcoming. Those methods pose some new challenges
for scientists. For example, choosing an optimal time lag requires
careful consideration in this multiscale context. Time lag selection
can, in part, be based on theoretically motivated temporal distance in
which the two processes are expected to be related. However, new
research questions may not carry that level of specificity. In this
case, it can also be a process of trial and error to determine the
maximum lag to include in the analysis using visual inspection. More
rigorously, there are other methods for determining a maximum time lag
using a critical value that is dependent on time scales [@shen2015]; we
expect those techniques might be generalized for MLRA as well. Table 3
below shows our initial plan for functions to include in future
iterations of the package. Of course, as the package becomes more
utilized, new ideas and resources may be come available to build on the
current functionality. To that end, we welcome feature requests and
collaborations to grow the package to meet the diverse needs of the
scientific community.

**Table 3**

*Overview of development plan for* `fractalRegression` *package*

| Function                                                  | Next Release | Future Release |
|-----------------------------------|-------------------|-------------------|
| DLCCA                                                     | X            |                |
| MLRA                                                      | X            |                |
| Chabra-Jensen's Direct Estimation of Multifractal Spectra | X            |                |
| Wavelet Based Fractal Analyses                            |              | X              |
| Multifractal Cross-Correlation Methods                    |              | X              |
| Advanced Detrending Methods                               |              | X              |
| Bayesian Estimation of Hurst Exponent                     |              | X              |
| Time Lag Optimization Function                            |              | X              |

: Table 3. Overview of development plan for `fractalRegression` package

# Conclusion

In this paper, we advance the `fractalRegression` R package as a new
tool for behavioral, cognitive, and social scientists from varied
backgrounds and provide examples of its use on simulated and empirical
data. We hope that in collating these methods, and making them
efficient, that they will be more accessible and systematically utilized
across disciplines. There are many unanswered questions about these
methods and the complex dynamics they characterize Our hope is that this
work inspires future efforts that not only apply these methods, but that
also expand on them to further our understanding of the complexities of
multiscale interactions in dynamic systems.

# Appendix 1: Fundamental Equations

In this appendix, we provide the corresponding equations given for
computation of the methods presented in this manuscript and implemented
in our package. There is a natural progression from DFA to DCCA and MRA
[@kristoufek2015; @likens2019]. That progression is given below,
starting with:

DFA

$F_X = \sqrt{\frac{\sum^{T-s+1}_{j-1}f^2_X(s,j)}{T-s}}$

where

$f^2_X(s,j) = \frac{\sum^{j+s-1}_{k=j}(X_k -\widehat{X}_{k,j})}{s-1}$

DCCA

$F_Y = \sqrt{\frac{\sum^{T-s+1}_{j-1}f^2_Y(s,j)}{T-s}}$

where

$f^2_Y(s,j) = \frac{\sum^{j+s-1}_{k=j}(Y_k -\widehat{Y}_{k,j})}{s-1}$

and the scale-wise covariance is estimated as:

$f^2_{XY}(s,j) = \frac{\sum^{j+s-1}_{k=j}(X_k -\widehat{X}_{k,j})(Y_k -\widehat{Y}_{k,j})}{s-1}$

which forms the basis for the scale-wise correlation coefficient
estimated as:

$\rho(s) = \frac{F^2_{XY}(s)}{F_X(s)F_Y(s)}$

and for the multi-scale regression coefficients, we replace the
denominator in the $\rho(s)$ equation with scale-wise variance of the
predictor to estimate the scale-wise regression coefficient from
regression $Y_t$ on $X_t$ as:

$\widehat{\beta}(s) = \frac{F^2_{XY}(s)}{F^2_X(s)}$

and where the variance of $\widehat{\beta}(s)$ is:

$\sigma_{\widehat{\beta}(s)}^2 = \frac{1}{T-2} \times \frac{F^2_u(s)}{F^2_Y(s)}$

and the scale-wise residual variance, $\widehat{F}^2_u(s)$ is estimated
by applying the DFA algorithm to all scale-wise residuals,
$\widehat{u}_t(s)$ as:

$\widehat{u}_t(s) = y_t - x_t\widehat{\beta}(s) - \overline{y_t - x_t\widehat{\beta}(s)}$.

MFDFA

The foundational equation for MFDFA is similar to that of DFA, following
notation from [@kantelhardtMultifractalDetrendedFluctuation2002], we
have

first a profile function for a given time series, $y(t)$

$Y(i) = \sum_{k=1}^i [x(k) - \bar{x}] \quad \textrm{for} \quad i = 1, 2, ..., N,$

where $x(i)$ is the original time series, $\bar{x}$ is its mean, and $N$
is the length of the time series.

As in DFA we divide the profile function into $N_s$ non-overlapping
windows of length $s$, and within each window, we fit a polynomial
function of order $m$ to remove trends and compute the variance

$F^2(v,s)=\frac{1}{s}\sum_{i=1}^{s}{Y[(v-1)s+i]}^2$

for each segment, $v, v=1,2,...N_s$ and

$F^2(v,s)=\frac{1}{s}\sum_{i=1}^{s}\{Y[N-(v-N_s)s+i]-y_v(i)\}^2$

where $y_v(i)$ is fitting polynomial of order \$m\$. Next, we average
over all segments to obtain the $q$th order fluctuation function

$F_q(s)=\{\frac{1}{2N_s}\sum_{v=1}{2N_s}[F^2(v,s)]^{q/2}\}^{1/q}$

where q can take any real value. Given that $F_q(s)$ generalizes the DFA
fluctuation function, \$F_X\$, given above, we are interested in
understanding how $F_q(s)$ changes with $s$ which we investigate with
log-log regressions of those quantities where we expect

$F_q(s)\sim s^{h(q)}$

where h(q) is the generalized Hurst exponent. Other fractal quantities
can be computed by transformations of $h(q)$. See
[@kantelhardtMultifractalDetrendedFluctuation2002] for details.

# Acknowledgments

Author AL receives support from a National Institutes of Health Center
grant (P20GM109090), National Science Foundation grant, National
Strategic Research Institute/Department of Defense, and the Nebraska
Collaboration Initiative.

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```
