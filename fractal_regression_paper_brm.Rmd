---
title             : "fractalRegression: An R package for multiscale regression and fractal analyses"
shorttitle        : "FRACTAL REGRESSION"
author: 
  - name          : "Aaron D. Likens"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "alikens@unomaha.edu"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Software
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Travis J. Wiltshire"
    affiliation   : "2"
    role:
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
      - Software
affiliation:
  - id            : "1"
    institution   : "Department of Biomechanics, University of Nebraska at Omaha"
  - id            : "2"
    institution   : "Department of Cognitive Science & Artificial Intelligence, Tilburg University"
authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.
  Enter author note here.
abstract: |
  Time series data from scientific fields as diverse as astrophysics, economics, human movement science, and neuroscience all exhibit fractal properties. That is, these time series often exhibit self-similarity and long-range correlations. This `fractalRegression` package implements a number of univariate and bivariate time series tools appropriate for analyzing noisy data exhibiting these properties. These methods, especially the bivariate tools [@kristoufekDetrendedFluctuationAnalysis2015; @likensStatisticalPropertiesMultiscale2019] have yet to be implemented in an open source and complete package for the R Statistical Software environment. As both practitioners and developers of these methods, we expect these tools will be of interest to a wide audience of scientists who use R, especially those from fields such as the human movement, cognitive, and other behavioral sciences. The algorithms have been developed in C++ using the popular Rcpp [@eddelbuettelRcppSeamlessIntegration2011] and RcppArmadillo [@eddelbuettelRcppArmadilloAcceleratingHighperformance2014] packages. The result is a collection of efficient functions that perform well even on long time series (e.g., $\geq$ 10,000 data points). In this work, we motivate introduce the package, each of the functions, and give examples of their use as well as issues to consider to correctly use these methods.
  
  
  <!-- https://tinyurl.com/ybremelq -->
keywords          : "long range correlation, fractal, multiscale, dynamics"
wordcount         : "X"
bibliography      : ["library.bib"]
floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  markdown: 
    wrap: 72
bibliography: library.bib #DELETE THIS BEFORE KNIT NEEDED FOR ZOTERO COMPATIBILITY
---

```{r setup, include = FALSE}
library("papaja")
library("fractalRegression")
library("ggplot2")
r_refs("library.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(424242)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

Over time, many signals from living and complex systems exhibit systematic regularities and dependencies across spatial and temporal scales [@kello2010]. These regularities often follow a power-law (i.e., self-similarity across scales) that are estimated using fractal analyses. Fractal analysis, in its many forms, has become an important framework in virtually every area of science, often serving as an indicator of system health [@goldbergerFractalDynamicsPhysiology2002], adaptability [@bakSelforganizedCriticalityExplanation1987], control [@likensExperimentalControlScaling2015], cognitive function [@eulerWorkingMemoryPerformance2016], and multi-scale interactions [@kelty-stephenThreadingMultifractalSocial2017].

In particular, various methods related to Detrended Fluctuation Analysis (DFA) [@pengMosaicOrganizationDNA1994] have rose to prominence due to their relative ease of understanding and broad applicability to stationary and non-stationary time series, alike. More specifically, in areas of the social and cognitive sciences, DFA, or variants of DFA, have been used to study, for example, reaction times [@vanordenSelforganizationCognitivePerformance2003], eye gaze [@stephenDynamicsInsightMathematical2009], gait [@hausdorffFractalDynamicsHuman1996, @deligni√®res2009], limb movements [@delignieresFractalModelsEventbased2008], heart rate [@goldbergerFractalDynamicsPhysiology2002], and neurophysiological oscillations [@hardstoneDetrendedFluctuationAnalysis2012, @schaworonkowLongitudinalChangesAperiodic2021, @eulerWorkingMemoryPerformance2016]. And, beyond an individual level, the methods have been used to study human-machine system interaction [@likensExperimentalControlScaling2015], tool use [@kelty-stephenMultifractalTemporalCorrelations2016, @favela2021], and interpersonal coordination in a variety of modalities [@davisMultiscaleInteractionsInterpersonal2016, @delignieresMultifractalSignaturesComplexity2016].

Thus, there is a broad scientific appeal for these fractal-based analyses. While, the basic DFA algorithm has been implemented in numerous packages and software programs, more advanced methods such as Multifractal Detrended Fluctuation Analysis (MFDFA) [@kantelhardtMultifractalDetrendedFluctuation2002], Detrended Cross Correlation (DCCA) [@zebendeDCCACrosscorrelationCoefficient2011; @podobnikDetrendedCrossCorrelationAnalysis2008], and, in particular, fractal regression techniques such as Multiscale Regression Analysis (MRA) [@kristoufekDetrendedFluctuationAnalysis2015; @likensStatisticalPropertiesMultiscale2019] have not yet been implemented in a comprehensive software package. Thus, there is a clear need for a package that incorporates this functionality in order to advance theoretical research focused on understanding the time varying properties of natural phenomena and applied research that uses those insights in important areas such as healthcare [@cavanaugh2017] and education [@snow2016]. In this work, we provide an overview of our `fractalRegression` package, provide simulated and empirical examples of it's functions, and provide practical advice on the successful application of these methods.

<!-- - Connect better to regression part (see 2019 paper from Aaron and Nia Multiscale regression intro and discussion) -->

# Package Overview

Our `fractalRegression` package for R [@rcoreteamLanguageEnvironmentStatistical2018] is built on a C++ architecture and includes a variety of uni- and bivariate fractal methods as well as functions for simulating data with known fractional properties (e.g., scaling, dependence, etc.), and surrogate testing. Some foundational efforts in fractal analyses, which partially overlap with the functionality of this package, have been implemented elsewhere. For example, a number of univariate fractal and multifractal analyses have been implemented in the 'fracLab' library for MATLAB [@legrand2003] and other toolboxes that are mainly targeted at multifractal analysis [@ihlen2010; @ihlenIntroductionMultifractalDetrended2012]. In terms of open access packages, there are other packages that implement some, but not all of the same functions such as the `fathon` package [@bianchi2020] that has been implemented in Python as well as the R packages: `fractal` [defunct], `nonlinearTseries` [@garciaNonlinearTseriesNonlinearTime2020], and `MFDFA` [@laibMultifractalAnalysisTime2018]. However, none of the above packages incorporate univariate monofractal and multifractal DFA with bivariate DCCA and MRA nor do they run on a C++ architecture. Our `fractalRegression` package is this unique in this combination of analyses and efficiency (particularly for long time series). For instance, we are not aware of any other packages that feature MRA and Multiscale Lagged Regression (MLRA). In addition, we expect that featuring simulation methods as well as surrogate testing strongly bolsters the accessibility of these methods for the social and cognitive science community in particular, but also science, more generally.

# Methodological Details and Examples

In order to demonstrate the methods within the 'fractalRegression' package, we group this into univariate (DFA, MFDFA) and bivariate methods (DCCA, MRA, MRLA). For each method, we 1) highlight the key question(s) that can be answered with that method, 2) briefly describe the algorithm with sources for additional details, 3) describe some key consideration for appropriately applying the algorithm, and demonstrate the use of the functions on a 4) simulated and 5) empirical application of the function. An overview of the functions included in the package, the general objective of that function, and the output are shown below in Table 1. The additional details are included in the sections corresponding to those methods, in the package documentation, and in the original sources for the methods.

**Table 1.**

*Overview of package functions, objectives, and output*

| Function      | Objective                                                                                                                         | Output                                                                                                                                                                           |
|-----------------|-----------------------|--------------------------------|
| `dfa()`       | Estimate long-range correlation in a time series                                                                                  | Object containing the overall $\alpha$ estimate and, if desired the `logScales` and `logRMS`                                                                                     |
| `mfdfa()`     | Estimate the magnitude and range of long-range correlations in a time series                                                      | Object containing the $\log_2$ scales used for the analysis, the $\log_2$ fluctuation function for each scale and $q$, the various q-order exponents, $Hq$, $Tau$, $h$, and $Dh$ |
| `dcca()`      | Estimates of scale-specific correlation between two time-series                                                                   | Object containing the scales used for the analysis and the $\rho$ '`rho'` values for each scale                                                                                  |
| `mra()`       | Estimates the scale specific regression coefficients for a predictor time series on and outcome time series                       | Object containing the scales and scale specific $\beta$ estimates, $R^2$, and $t$ statistics                                                                                     |
| `mlra()`      | Estimates the scale specific regression coefficients for a predictor time series on and outcome time series at pre-specified lags | Object with lag-specific $\beta$ coefficients                                                                                                                                    |
| `fgn_sim()`   | Simulate univariate fractional Gaussian noise                                                                                     | Returns a vector of length `n` according to the specified `H` Hurst exponent                                                                                                     |
| `mBm_mGn()`   | Simulate univariate multi-fractional Brownian motion and Gaussian noise                                                           | Returns two vectors of length `N` according to the specified $H_t$ series                                                                                                        |
| `mc_ARFIMA()` | Simulate various types of bivariate correlated noise processes.                                                                   | Returns two vectors of length `N` according to the specified noise `process` and parameters                                                                                      |
| `iaaft()`     | Generate surrogate series using the iterative amplitude adjusted Fourier transform                                                | Returns a vector of same length as input time series                                                                                                                             |

## Univariate Methods

### Detrended Fluctuation Analysis

The key question that can be answered by Detrended Fluctuation Analysis (DFA) [@pengMosaicOrganizationDNA1994] is: *what is the magnitude and direction of long range correlation in a single time series?* While DFA has been described extensively elsewhere [@kantelhardtDetectingLongrangeCorrelations2001] and visualized nicely [@kelty-stephenMultifractalTemporalCorrelations2016], we provide a brief summary here. DFA entails splitting a time series into several small bins (e.g., 16). In each bin, the least squares regression is fit and subtracted within each window. Residuals are squared and averaged within each window. Then, the square root is taken of the average squared residual across all windows of a given size. This process repeats for larger window sizes, growing by, say a power of 2, up to N/4, where N is the length of the series. In a final step, the logarithm of those scaled root mean squared residuals (i.e., fluctuations) is regressed on the logarithm of window sizes. The slope of this line is termed $\alpha$ and it provides a measure of the long range correlation. $\alpha$ is commonly used an as estimator of the Hurst exponent (H), where $\alpha<1$ = $H$, and for $\alpha>1$, $H = 1 - \alpha$. Conventional interpretation of $\alpha$ is: $\alpha < 0.5$ is anti-correlated, $\alpha ~= 0.5$ is uncorrelated, white noise, $\alpha > 0.5$ is temporally correlated, $\alpha ~= 1$ is long-range correlated, 1/f-noise, pink noise, $\alpha > 1$ is non-stationary and unbounded, and $\alpha ~= 1.5$ is fractional brownian motion.

#### DFA Examples

To demonstrate the use of `dfa()` we simulate three time series using the `fgn_sim()` function. This is a simple function based on the former `fARMA` R package. It only requires the number of observations `n`, and the Hurst exponent `H`. In particular, we simulate white noise, pink noise, and anti-correlated fractional Gaussian noise using the code below.

```{r, echo = TRUE}

white.noise <- rnorm(5000)

pink.noise <- fgn_sim(n = 5000, H = 0.9)

anti.corr.noise <- fgn_sim(5000, H = 0.25)

scales <- logscale(scale_min = 16, scale_max = 1024, scale_ratio = 2)
```

Then, we can run DFA on these using the example code below. Note that this example uses a linear detrending with minimum scale of 16, a maximum scale that is at most 1/4 the time series length, and logarithmically spaced scale factor (`scale_ratio`) of 2.

```{r, echo = TRUE}
dfa.white <- dfa(x = white.noise, order = 1, verbose = 1, scales=scales, scale_ratio = 2)

dfa.pink <- dfa(x = pink.noise, order = 1, verbose = 1,
scales=scales, scale_ratio = 2)

dfa.anti.corr <- dfa(x = anti.corr.noise, order = 1, verbose = 1, scales=scales, scale_ratio = 2)
```

In terms of output from the above examples, for white noise, we observed that $\alpha$ = `r dfa.white$alpha`, for pink noise we observed that $\alpha$ = `r dfa.pink$alpha`, and since we simulated anti-correlated noise with H = 0.25, we observed a close estimate of the $\alpha$ = `r dfa.anti.corr$alpha`. In terms of the objects saved from the `dfa()` function, one commonly inspects the `log_scales`-`log_rms` plots. Given the estimates above, we see in Figure 1 that the slopes for white noise, pink noise, and anti-correlated noise conform to our expectations. These slop estimates are provided n the equation listed above each respective line, and are generated using the `dfa.plot()` function.

**Figure 1**

*Log scale-Log fluctuation plots for white noise (top), pink noise (middle), and anti-correlated noise (bottom)*

```{r, echo = TRUE}
par(mfrow=c(3,1))
dfa.plot(dfa.white)
dfa.plot(dfa.pink)
dfa.plot(dfa.anti.corr)
```

For an empirical example, we apply the `dfa()` function to the Human Balance Dataset @santos2016. DESCRIBE DATA HERE. We chose this dataset because postural sway data are known to exhibit interesting fractal dynamics (CITES) and we can systematically evaluate the data for all of the univariate and bivariate analyses detailed in this work. Importantly, regarding the question one can ask using DFA, we observe that ANSWER TO QUESTION HERE.

```{r}

```

**Figure 2**

*Log scale-Log fluctuation plots for empirical time series (ADD ME)*

### Multifractal Detrended Fluctuation Analysis

Multifractal Detrended Fluctuation Analysis (MFDFA; @kantelhardtMultifractalDetrendedFluctuation2002) is an extension of DFA by generalizing the fluctuation function to a range of exponents of the $q$th order. The key question that can be answered by MFDFA is: *how does the magnitude and direction of long range correlation change over time within a single time series?* Like DFA, MFDFA entails splitting a time series into several small bins (e.g., 16). In each bin, the least squares regression is fit and subtracted within each window. However, the residuals are raised to a range of exponents $q$ and averaged within each window. So when $q = 2$, DFA is equal to MFDFA. When $q >2$, larger residual are emphasized and when $q < 2$, smaller residuals are emphasized. The rest of the DFA algorithm is performed for each window and windows size for all values of $q$. We refer the reader to the work of Kelty-Stephens and colleagues @kelty-stephenMultifractalTemporalCorrelations2016 Figure 3 for a visualization of the algorithm and to Kantelhardt and colleagues @kantelhardtMultifractalDetrendedFluctuation2002 for additional mathematical description.

### MFDFA Examples

To demonstrate the use of `mfdfa()`, we work with data included in our package (`fractaldata`), that was originally provided by @ihlenIntroductionMultifractalDetrended2012 . It includes a white noise time series, monofractal time series, and a multifractal time series.

**Figure 3**

*Time series from Ihlen (2012) corresponding to white noise, monofractal, and multifractal series.*

```{r, echo=FALSE}
# Load the data
data("fractaldata")

white.plot <- ggplot(fractaldata, aes(y=whitenoise, x=time))+geom_line()+ggtitle("white noise")+ylab("signal amplitude")

mono.plot <- ggplot(fractaldata, aes(y=monofractal, x=time))+geom_line()+ggtitle("monofractal")+ylab("signal amplitude")

multi.plot <- ggplot(fractaldata, aes(y=multifractal, x=time))+geom_line()+ggtitle("multifractal")+ylab("signal amplitude")

gridExtra::grid.arrange(white.plot,mono.plot,multi.plot,nrow=3)
```

Performing MF-DFA is relatively straight forward with the `mfdfa()` function. As shown in the example below, one needs to enter the time series `x` to perform the analysis on, the range of `q` order exponents to use, the `order` of polynomial detrending, and the `scales` for the analysis. In this case, we define our `scales` by choosing logarithmically spaced scales and we select values of q from -5 to 5.

```{r, echo=TRUE}

scales <- logscale(scale_min = 16,scale_max = 1024,scale_ratio = 1.1)

white.mf.dfa.out <- mfdfa(x = fractaldata$whitenoise, q = c(-5:5), order = 1, scales=scales)

mono.mf.dfa.out <- mfdfa(x = fractaldata$monofractal, q = c(-5:5), order = 1,  scales=scales)

multi.mf.dfa.out <- mfdfa(x = fractaldata$multifractal, q = c(-5:5), order = 1,  scales=scales)

```

A common way to understand if there is evidence of multifractality is to examine a plot showing the slopes of the `log_fq` at the `log_scale` values. If all the plots have the same slope, that provides evidence of monofractality. If there are distinct slopes, then there is evidence of multifractality. It's also important to check here that the slopes of `log_scale` and `log_fq` are largely linear, thus implying that they are scale invariant. If not, then it could be the case that a higher order polynomial detrending is appropriate (see Kantelhardt et al., 2001). Figure 4 shows what we would expect for a monofractal and multifractal signal. In other words, the monofractal signal shows a consistent slope, whereas the multifractal signal shows variability in the slopes.

**Figure 4**

*mfdfa.plots for mono-(top) and multifractal series (bottom). The four panels correspond to DETAILS HERE.*

```{r, echo=FALSE}
mfdfa.plot(mono.mf.dfa.out)
mfdfa.plot(multi.mf.dfa.out)
```

A common metric for comparing the multifractal spectrum is to calculate the width ($W$) as $h_{max} - h_{min}$. Let's do this to compare the monofractal and multifractal time series. We observe in this case that for the monofractal signal $W_{mono} =$ `r max(mono.mf.dfa.out$h) - min(mono.mf.dfa.out$h)` and $W_{multi} =$ `r max(multi.mf.dfa.out$h) - min(multi.mf.dfa.out$h).` If plot the multifractal spectra D(h) against h, we clearly observe the difference in the widths of the multifractal spectra for the mono- and multifractal signals, as shown in Figure 4 above.

For our empirical analysis, we again turn to the postural data. We set out parameters appropriate for the data and run `mfdfa()`.

```{r}

```

#### DFA and MFDFA Considerations

We recommend a few points of consideration here in using this function. One is to be sure to evaluate whether there are cross-over points in the log scale-log fluctuation plots [@pengMosaicOrganizationDNA1994; @perakakis2009]. Cross-over points (or a visible change in the slope as a function of scale) indicate that a mono-fractal characterization does not sufficiently characterize the data. If cross-over points are evident, we recommend proceeding to estimate the two scaling regions with a piece-wise regression.

While it is common to use only linear detrending with DFA, it is important to inspect the trends in the data to determine if it would be more appropriate to use a higher order polynomial for detrending, and/or compare the DFA output for different polynomial orders [@kantelhardtDetectingLongrangeCorrelations2001].

General recommendations for choosing the min and max scale are minimum scale of 10 and a maximum scale of N/4, where N is the total number of observations in the signal. See Eke et al. (2002) [@ekeFractalCharacterizationComplexity2002] and Gulich and Zunino (2014) [@gulichCriterionDeterminationOptimal2014] for additional considerations.

## Bivariate Methods

### Detrended Cross-Correlation Analysis

Detrended Cross-Correlation Analysis (DCCA; @podobnikDetrendedCrossCorrelationAnalysis2008, @zebendeDCCACrosscorrelationCoefficient2011 ) is a bivariate extension of the DFA algorithm generalizing it to a correlational case between two time series that may be non-stationary. The key questions that can be asked with it are: a) *How does correlation between two time series change as a function of scale?* and b) *What is/are the dominant (time) scale(s) of coordination? (those that are beyond a threshold, or statistically significant given a criteria, or of a certain magnitude?* For DCCA, the DFA algorithm gets applied to both time series providing the scale-wise estimates for both. DESCRIBE DCCA ALGORITHM HERE. Whereas in DFA, the key metric is $\alpha$, in DCCA, one estimates the scale-specific, detrended cross-correlation coefficient $\rho$ for the pair of time series.

#### DCCA Examples

To demonstrate the use of `dcca()`, we used the `mc_arfima()` function from our package to simulate two time series with known properties. Specifically, we use the multicorrelated ARFIMA examples from Kristoufec's work [@kristoufekMixedcorrelatedARFIMAProcesses2013]. In this case, we use the parameters from Kristoufec (2013) for Model 1 (p. 6,487), that generates two time series of length 10,000 that exhibit long range correlations (LRC) as well as long range cross-correlations (LRCC). The code for simulating these two time series is shown below. Additionally, Figure #, shown below, visualizes a subset of these time series.

```{r message=FALSE}
set.seed(987345757)

sim1 <- mc_ARFIMA(process="Mixed_ARFIMA_ARFIMA", alpha = 0.2, beta = 1, gamma = 1, delta = 0.2, n = 10000, d1 = 0.4, d2 = 0.3, d3 = 0.3, d4=0.4, rho=0.9)

```

**Figure \#**

*Subset of two time series exhibiting long range correlation and long range cross-correlation*

```{r, echo=FALSE}

plot(sim1[2000:3000,1],type='l', ylab= "Signal Amplitude", xlab='Time', main = "MC-ARFIMA with LRC and LRCC")

lines(sim1[2000:3000,2], col='blue')
```

To perform the `dcca()` on these time series, we could use the code below, where we first define the `scales` using using the `logScale()` function from the `ifultools` package [@constantine2021] to define a set of logarithmically spaced scales to use for the analysis.

```{r}
scales <- ifultools::logScale(scale.min = 10, scale.max = 1000, scale.ratio = 1.1)

dcca.out.arfima <- dcca(sim1[,1], sim1[,2], order = 1, scales = scales)
```

From here, we can visualize the output of the analysis as shown below in Figure #. We observe that, as expected, the correlation between the MC-ARFIMA processes are consistently high (all $\rho$'s $> .8$) and continue to be high at increasing time scales. We also add standard errors plotted around each point, but note these are based on one simulation only and more robust estimates of standard error could be calculated using many time series.

**Figure \#**

*DCCA output for long range correlation and long range cross-correlation*

```{r, echo=FALSE}
dcca.out.arfima <- as.data.frame(dcca.out.arfima)

error <- sd(dcca.out.arfima$rho)/sqrt(length(dcca.out.arfima$rho))

dcca.plot <- ggplot(data=dcca.out.arfima, aes(x=scales,y=rho)) + geom_point() +geom_line() + ggtitle("DCCA on MC-ARFIMA processes with LRC and LRCC")+ geom_pointrange(aes(ymin=rho-error,ymax=rho+error))

#geom_smooth(method=lm, formula = y ~ poly(x, 2), se = TRUE)

dcca.plot
```

As a point of comparison, we can generate a time series in contrast with this that exhibits processes with LRC and short-range cross-correlation (SRCC) using the code below. In contrast to the previous DCCA analysis, Figure \# shows a signal that begins with a high cross-correlation ($\rho$'s $> .6$) , but that begins to deviate and trend substantially lower at increasing scale sizes approaching $\rho = 0$.

```{r}
sim2 <- mc_ARFIMA(process="Mixed_ARFIMA_AR", alpha = 1,beta = 1,gamma = 1,delta = 1,n =10000,d1=0.4,d2=0.4,theta1=0.8,theta2=0.8,rho=0.9)
```

**Figure \#**

*DCCA output for long range correlation and short range cross-correlation*

```{r, echo=FALSE}
scales <- ifultools::logScale(scale.min = 10, scale.max = 1000, scale.ratio = 1.1)
dcca.out.arfima2 <- dcca(sim2[,1], sim2[,2], order = 1, scales = scales)
dcca.out.arfima2 <- as.data.frame(dcca.out.arfima2)
error <- sd(dcca.out.arfima2$rho)/sqrt(length(dcca.out.arfima2$rho))
dcca.plot2 <- ggplot(data=dcca.out.arfima2, aes(x=scales,y=rho)) + geom_point() +geom_line() + ggtitle("DCCA on MC-ARFIMA processes with LRC and SRCC") + geom_pointrange(aes(ymin=rho-error,ymax=rho+error))
dcca.plot2
```

-   Empirical data: EPICLE Movement Data?

### Multi-scale Regression Analysis

Multi-scale regression analysis (MRA) is an adaptation of DCCA that brings the analyses into a predictive, regression framework @kristoufek2015 . The key questions that can be answered by it are: a) *How does the influence of one time series on another time series change as a function of scale?* and b) *What is/are the dominant (time) scale(s) of influence of one time series on another time series?* The algorithm is largely the same as DCCA, with a key difference being that instead of estimating scale-wise symmetric correlation coefficients, leveraging methods of Ordinary Least Squares (OLS) regression, asymmetric $\beta$ coefficients are estimated (see @likens2019; @kristoufek2015 ).

#### MRA Examples

Considering the LRC and LRCC simulations used for DCCA, we can examine whether the scale-wise fluctuations of one variable can predict the scale-wise fluctuations of the other using `mra()`. As with a traditional regression approach, we will use one of our variables as our predictor ($x_t$) and the other as our outcome ($y_t$). In the example below, we again first define our logarithmically spaced scales. We then apply the `mra()` function to the two simulated time series. In this case, it's important to specify which is variable is `x` (the predictor) and which is `y` (the outcome). For ease of plotting, we convert this to a dataframe in the process.

```{r}
scales <- logScale(scale.min = 10, scale.max = 1000, scale.ratio = 1.1)

mra.out <- as.data.frame(mra(x = sim1[,1], y = sim1[,2],order = 1, scales = scales))
```

We can then visualize these results as shown below in Figure #. Generally, we observe that the $\beta$ coefficients are relatively stable at increasing time scales with a general, perhaps quadratically increasing trend. Here it is also important to investigate the change in $R^2$ as well as the $t$-values. Below we see that the $R^2$ is quite high at most of the time scales with $R^2_{min} =$ `r round(min(mra.out$r2),2)` and $R^2_{max} =$ `r round(max(mra.out$r2),2)` and all of the $t$-values greater than the conventional cut-off at 1.96. So between these two component ARFIMA processes, the output of MRA shows that much of the scale specific variance in $y_t$ is explained and predicted by $x_t$.

**Figure \#**

*MRA output for long range correlation and long range cross-correlation*

```{r echo=FALSE}
error <- sd(mra.out$betas)/sqrt(length(mra.out$betas))
mra.plot <- ggplot(data=mra.out, aes(x=scales,y=betas)) + geom_point() +geom_line() +ggtitle("Multiscale Regression Analysis for MC-ARFIMA with LRC and LRCC") + geom_pointrange(aes(ymin=betas-error,ymax=betas+error))
#geom_smooth(method=lm, formula = y ~ poly(x, 2), se = TRUE)
mra.plot
```

-   Empirical data: FNIRS from Aaron?

### Multi-scale Lagged Regression Analysis

Multi-scale lagged regression analysis is an extension of MRA that allows for examining the influence as a function of scale, but also of time lag. In particular, the key questions that can be asked with MLRA are: a) *How does the influence of one time series on another time series change as a function of scale at different time lags?* and b) *Does the dominant time scale of influence change over successive time lags?* DESCRIBE MLRA ALGORITHM HERE.

#### MLRA Examples

-   MLRA

    -   Key Question
    -   Simulated data: Equation from Aaron from grant on MLRA
    -   Empirical data: FNIRS from Aaron?

## Surrogate Methods

In all of the above methods, one gets either a single estimate of a parameter (e.g., $\alpha$) or a range of estimates (e.g., $\rho$, $\beta$). While those estimates are meaningful in and of themselves, it is common practice to perform some form of null hypothesis test regarding the estimate. These are generally referred to as surrogate methods @kantz2003 . We present several options here that could be ranked in terms of increasing levels of rigor: randomized surrogates, iterative amplitude adjusted Fourier transformed (IAAFT) surrogates, and model based surrogates.

### Randomized Surrogates

Randomized surrogates generally involve randomly shuffling the order of values of a time series. The idea is generally that the temporal structure is destroyed, yet the other features of the time series still exist [@kantelhardtMultifractalDetrendedFluctuation2002]. Note that additional options exist along these lines (see for example [@dumasInterBrainSynchronizationSocial2010]). The key comparison here would be to compare the estimates extracted from a given analysis (e.g., DFA) on the observed sample of data with the estimates derived from and equally sized sample of the surrogate series (see @kantz2003 @moulder2018 @wiltshire2019 for examples).

```{r}
rand.surr <- permute::shuffle(pink.noise)

dfa.rand.surr <- dfa(x = rand.surr, order = 1, verbose = 1, scales = scales, scale_ratio = 2)
```

Randomizing the pink noise time series, which originally exhibited long range correlation ($\alpha$ = `r dfa.pink$alpha`), and performing DFA on it, now provides an estimate of $\alpha$ = `r dfa.rand.surr$alpha`, which is consistent with a random or white noise process. These values are clearly different, however, performing inferential statistics on a sample of observed estimates compared to surrogate estimates would provide compelling evidence that the temporal dynamics suggested by the observed estimates are different than those derived from a random process.

### Iterative Amplitude-Adjusted Fourier Transform Surrogates (IAAFT)

The IAAFT algorithm was originally developed as a way to be able to evaluate, whether there is nonlinearity [@schreiber1996]. More recently, it was proposed as a technique that could be use to see whether multifractal indices suggest interaction across scales [@ihlen2010]. Like with randomized shuffling, estimates derived from IAAFT surrogates should be also be different from the estimates derived from the empirical time series. Although in this case, the comparison is typically made between the multifractal spectra of the observed time series, and the spectra from a set of IAAFT surrogate series.

In the code below, we provide an example for generating IAAFT surrogates using the `iaafft()` function in the package. One enters the `signal`, which is the observed time series, and `N`, the number of surrogates to generate. There are a number of options here but a common number of surrogates is 19 [@kantz2003]. Common practice is that surrogates are generated from many observed time series, but here we illustrate using only a single time series: the multifractal signal used previously in the MFDFA example. Then we use the same parameters for the `mfdfa()` function, but apply it to all of the IAAFFT surrogates.

```{r}

iaafft.surr <- iaafft(fractaldata$multifractal, N = 19)

iaafft.surr.out <- apply(iaafft.surr, MARGIN = 2, FUN = mfdfa, q = c(-5:5), order = 1, scales=scales)

```

```{r, echo=FALSE}
# maybe there is a more efficient way to do this with apply?
for (i in 1:length(iaafft.surr.out)){
  mf.width.temp <- max(iaafft.surr.out[[i]]$h) - min(iaafft.surr.out[[i]]$h)
  if (i == 1){
    mf.width <- mf.width.temp
  } else {
    mf.width <- rbind(mf.width,mf.width.temp)
  }
}
```

Assuming we were using IAAFFT to compare the multifractal width ($W$) between the observed signal and the surrogate signals, recall that the observed widith was $W_{multi} =$ `r max(multi.mf.dfa.out$h) - min(multi.mf.dfa.out$h)`. Now, we can calculate the average multifractal width across all of the generated surrogates and we observe that $W_{surr} =$ `r mean(mf.width`), which is narrower than the spectrum from the multifractal signal. In practice, there are many surrogate options [@moulder2018], but, again, inferential statistics are commonly performed to compare observed estimates to the surrogate estimates to bolster evidence of the inferred dynamics.

### Model-based Surrogates

-   Model based surrogate (Simulated exponents) - See Likens 2019 paper with model of postural sway/control, taking an educated guess about the data generating process underlying the time series. Estimates should not be different. See Roume et al 2018 windowed detrended CCA
-   Can we incorporate lags into MC-ARFIMA?

# General Discussion

-   General value of methods and the types of questions (mention the types of data used in empirical examples.

-   Practical consideration of univariate methods

    -   Length of time series

-   Practical consideration of bivariate methods

    -   Length of time series

    -   Likens et al. 2019 found positive bias of linear and quadratic trends on MRA beta estimates at larger scales that could be mitigated with larger detrending order. This involves checking the time series with time as a predictor and polynomials.

-   Unique contribution of the methods

# Appendix 1: Fundamental Equations

Here we will insert the fundamental equations for showcasing the algorithms. WE NEED Lagged functions and MFDFA.

DFA

$F_X = \sqrt{\frac{\sum^{T-s+1}_{j-1}f^2_X(s,j)}{T-s}}$

where

$f^2_X(s,j) = \frac{\sum^{j+s-1}_{k=j}(X_k -\widehat{X}_{k,j})}{s-1}$

DCCA

$F_Y = \sqrt{\frac{\sum^{T-s+1}_{j-1}f^2_Y(s,j)}{T-s}}$

where

$f^2_Y(s,j) = \frac{\sum^{j+s-1}_{k=j}(Y_k -\widehat{Y}_{k,j})}{s-1}$

and the scale-wise covariance is estimated as:

$f^2_{XY}(s,j) = \frac{\sum^{j+s-1}_{k=j}(X_k -\widehat{X}_{k,j})(Y_k -\widehat{Y}_{k,j})}{s-1}$

which forms the basis for the scale-wise correlation coefficient estimated as:

$\rho(s) = \frac{F^2_{XY}(s)}{F_X(s)F_Y(s)}$

and for the multi-scale regression coefficients, we replace the denominator in the $\rho(s)$ equation with scale-wise variance of the predictor to estimate the scale-wise regression coefficient from regression $Y_t$ on $X_t$ as:

$\widehat{\beta}(s) = \frac{F^2_{XY}(s)}{F^2_X(s)}$

and where the variance of $\widehat{\beta}(s)$ is:

$\sigma_{\widehat{\beta}(s)}^2 = \frac{1}{T-2} \times \frac{F^2_u(s)}{F^2_Y(s)}$

and the scale-wise residual variance, $\widehat{F}^2_u(s)$ is estimated by applying the DFA algorithm to all scale-wise residuals, $\widehat{u}_t(s)$ as:

$\widehat{u}_t(s) = y_t - x_t\widehat{\beta}(s) - \overline{y_t - x_t\widehat{\beta}(s)}$

# Acknowledgments

Author AL receives support from a National Institutes of Health Center grant (P20GM109090).

\newpage

# References

```{=tex}
\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
```
::: {#refs custom-style="Bibliography"}
:::

```{=tex}
\endgroup
```
